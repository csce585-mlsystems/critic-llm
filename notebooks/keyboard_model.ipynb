{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rho_plus as rp\n",
    "\n",
    "is_dark = False\n",
    "theme, cs = rp.mpl_setup(is_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "from critic.kbd_layout import QWERTY\n",
    "from critic.kbd_model import KbdModel\n",
    "from critic.string_alignment import all_paths\n",
    "from critic.corrector import Corrections\n",
    "from dataclasses import dataclass\n",
    "from keras import ops\n",
    "import pickle\n",
    "\n",
    "@dataclass\n",
    "class CorrectionResult:\n",
    "    true: str\n",
    "    typed: str\n",
    "    corrs: Corrections\n",
    "    context: str\n",
    "    time: float\n",
    "\n",
    "class AdjustedKbdModel(KbdModel):\n",
    "    def call(self, inputs):\n",
    "        X, same_i, true_i, lm_probs = inputs\n",
    "        probs = self.log_prob(X[:, 2], X[:, 3:5], X[:, 5:7])\n",
    "        path_log_probs = ops.segment_sum(probs, X[:, 1], num_segments=1000)\n",
    "        path_corr_is = ops.segment_max(X[:, 0], X[:, 1], num_segments=1000)\n",
    "        \n",
    "        yhat = ops.segment_max(path_log_probs, path_corr_is, num_segments=100)\n",
    "        yhat = ops.log_softmax(yhat.at[same_i].set(0).at[-1].set(-np.inf) + ops.log(lm_probs))\n",
    "\n",
    "        return -yhat[true_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CorrectionResult(true='million', typed='million', corrs=Corrections(words=['million', 'mullion', 'millions', 'gillion', 'pillion', 'billion', 'zillion', 'mil lion', 'mil-lion', 'mill ion', 'mill-ion', 'milling', 'milliner'], probs=array([8.77737983e-01, 5.09121721e-07, 1.06132202e-03, 1.50707586e-06,\n",
       "       1.10553320e-05, 1.20752210e-01, 2.17134659e-04, 1.20400661e-07,\n",
       "       1.74372439e-08, 1.29610905e-06, 1.37476171e-07, 2.05762160e-04,\n",
       "       1.09456924e-05])), context='1.5 ', time=0.5459755449555814)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = QWERTY\n",
    "\n",
    "with open('results/lm_probs.pkl', 'rb') as f:\n",
    "    lms = pickle.load(f)\n",
    "\n",
    "lms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from critic.string_alignment import align, all_paths\n",
    "\n",
    "\n",
    "inputs = []\n",
    "for res in lms[::10]:\n",
    "    if res.true not in res.corrs.words:\n",
    "        continue\n",
    "\n",
    "    corrs = res.corrs.as_series().sort_values(ascending=False)[:100]\n",
    "    true_i = np.argmax(corrs.index == res.true)\n",
    "    same_i = np.argmax(corrs.index == res.typed) if res.typed in corrs.index else -1\n",
    "\n",
    "\n",
    "    X = []\n",
    "    i = 0\n",
    "    for corr_i, word in enumerate(corrs.index):\n",
    "        edit_paths = align(res.typed, word)    \n",
    "        paths = all_paths(max(edit_paths.keys()), edit_paths)    \n",
    "\n",
    "        x0s = []\n",
    "        x1s = []\n",
    "        x2s = []\n",
    "        xis = []\n",
    "        xcs = []\n",
    "        for path_i, path in enumerate(paths):\n",
    "            x0 = []\n",
    "            x1 = []\n",
    "            x2 = []\n",
    "            for edit in path:\n",
    "                if edit is not None:\n",
    "                    kind, wrong, right = edit.as_numerical(layout)\n",
    "                    x0.append(kind)\n",
    "                    x1.append(list(wrong))\n",
    "                    x2.append(list(right))\n",
    "\n",
    "            if sum(ops.array(x0).shape) > 0:\n",
    "                x0s.append(ops.array(x0))\n",
    "                x1s.append(ops.array(x1))\n",
    "                x2s.append(ops.array(x2))\n",
    "                xcs.append(ops.zeros_like(x0s[-1]) + corr_i) \n",
    "                xis.append(ops.zeros_like(x0s[-1]) + i)                \n",
    "                i += 1\n",
    "\n",
    "\n",
    "        if ops.array(xis).nbytes > 0:        \n",
    "            X0, X1, X2, Xi, Xc = list(map(np.concat, (x0s, x1s, x2s, xis, xcs)))\n",
    "            row = ops.concatenate((Xc[:, None], Xi[:, None], X0[:, None], X1, X2), axis=1)\n",
    "            X.append(row)\n",
    "\n",
    "    X = ops.concatenate(X, axis=0)        \n",
    "    inputs.append([X, ops.array([same_i]), ops.array([true_i]), ops.array(np.pad(corrs.values, (0, 100 - len(corrs))))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - loss: 0.2544\n",
      "Epoch 2/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - loss: 0.2474    \n",
      "Epoch 3/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - loss: 0.2409  \n",
      "Epoch 4/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - loss: 0.2347  \n",
      "Epoch 5/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - loss: 0.2290  \n",
      "Epoch 6/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - loss: 0.2236  \n",
      "Epoch 7/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - loss: 0.2185   \n",
      "Epoch 8/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 0.2138  \n",
      "Epoch 9/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - loss: 0.2094   \n",
      "Epoch 10/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 0.2052  \n",
      "Epoch 11/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.2013  \n",
      "Epoch 12/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.1976  \n",
      "Epoch 13/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - loss: 0.1942   \n",
      "Epoch 14/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 0.1909   \n",
      "Epoch 15/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - loss: 0.1879   \n",
      "Epoch 16/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 0.1850   \n",
      "Epoch 17/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.1822   \n",
      "Epoch 18/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - loss: 0.1797  \n",
      "Epoch 19/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - loss: 0.1772   \n",
      "Epoch 20/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - loss: 0.1749  \n",
      "Epoch 21/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - loss: 0.1728   \n",
      "Epoch 22/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - loss: 0.1707   \n",
      "Epoch 23/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - loss: 0.1688  \n",
      "Epoch 24/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.1670 \n",
      "Epoch 25/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.1653   \n",
      "Epoch 26/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 0.1637   \n",
      "Epoch 27/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - loss: 0.1622  \n",
      "Epoch 28/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.1607  \n",
      "Epoch 29/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - loss: 0.1594\n",
      "Epoch 30/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - loss: 0.1581  \n",
      "Epoch 31/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 0.1570  \n",
      "Epoch 32/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.1559  \n",
      "Epoch 33/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - loss: 0.1548  \n",
      "Epoch 34/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - loss: 0.1539  \n",
      "Epoch 35/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.1530  \n",
      "Epoch 36/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.1521\n",
      "Epoch 37/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.1514   \n",
      "Epoch 38/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.1507   \n",
      "Epoch 39/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.1500   \n",
      "Epoch 40/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 0.1494   \n",
      "Epoch 41/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - loss: 0.1489   \n",
      "Epoch 42/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 0.1484   \n",
      "Epoch 43/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - loss: 0.1480  \n",
      "Epoch 44/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - loss: 0.1476  \n",
      "Epoch 45/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - loss: 0.1473   \n",
      "Epoch 46/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - loss: 0.1470   \n",
      "Epoch 47/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - loss: 0.1468   \n",
      "Epoch 48/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - loss: 0.1466   \n",
      "Epoch 49/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - loss: 0.1465  \n",
      "Epoch 50/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 0.1464  \n",
      "        loss\n",
      "0   0.285185\n",
      "1   0.277320\n",
      "2   0.269966\n",
      "3   0.263085\n",
      "4   0.256656\n",
      "5   0.250652\n",
      "6   0.245041\n",
      "7   0.239791\n",
      "8   0.234877\n",
      "9   0.230271\n",
      "10  0.225952\n",
      "11  0.221899\n",
      "12  0.218093\n",
      "13  0.214516\n",
      "14  0.211154\n",
      "15  0.207992\n",
      "16  0.205016\n",
      "17  0.202216\n",
      "18  0.199580\n",
      "19  0.197098\n",
      "20  0.194761\n",
      "21  0.192560\n",
      "22  0.190489\n",
      "23  0.188539\n",
      "24  0.186704\n",
      "25  0.184979\n",
      "26  0.183357\n",
      "27  0.181834\n",
      "28  0.180404\n",
      "29  0.179064\n",
      "30  0.177809\n",
      "31  0.176636\n",
      "32  0.175541\n",
      "33  0.174521\n",
      "34  0.173574\n",
      "35  0.172696\n",
      "36  0.171885\n",
      "37  0.171140\n",
      "38  0.170458\n",
      "39  0.169836\n",
      "40  0.169274\n",
      "41  0.168771\n",
      "42  0.168325\n",
      "43  0.167935\n",
      "44  0.167599\n",
      "45  0.167317\n",
      "46  0.167088\n",
      "47  0.166912\n",
      "48  0.166788\n",
      "49  0.166716\n",
      "{ 'adjusted_kbd_model': { 'aspect_ratio': Array(-0.04823992, dtype=float32),\n",
      "                          'oist': Array([-0.5327565 ,  0.37674445,  0.10204386,  0.5753594 ], dtype=float32),\n",
      "                          'power': Array(2.061372, dtype=float32),\n",
      "                          'scale': Array(0.5564211, dtype=float32),\n",
      "                          'tilt': Array(0.1372305, dtype=float32),\n",
      "                          'two_hand': Array(0.01919975, dtype=float32),\n",
      "                          'vowel': Array(0.39179283, dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from pprint import pprint\n",
    "\n",
    "from keras.optimizers.schedules import PolynomialDecay\n",
    "\n",
    "keras.config.disable_traceback_filtering()\n",
    "\n",
    "\n",
    "def dl():\n",
    "    while True:\n",
    "        for x in inputs:\n",
    "            yield (x, ops.array([0.0]))\n",
    "\n",
    "def fit(epochs=50):\n",
    "    mod = AdjustedKbdModel()    \n",
    "    mod(next(dl())[0])\n",
    "\n",
    "    steps_in_epoch = len(inputs)\n",
    "\n",
    "    decay_steps = steps_in_epoch * epochs\n",
    "\n",
    "    def log_prob_loss(y_true, y_pred):\n",
    "        return y_pred\n",
    "\n",
    "    mod.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(\n",
    "            learning_rate=PolynomialDecay(\n",
    "                4e-4, decay_steps, end_learning_rate=1e-6\n",
    "            ),\n",
    "            global_clipnorm=1.0,\n",
    "        ),\n",
    "        loss=log_prob_loss,\n",
    "    )\n",
    "\n",
    "    history = mod.fit(\n",
    "        dl(),\n",
    "        steps_per_epoch=steps_in_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "\n",
    "    print(pd.DataFrame(history.history))\n",
    "\n",
    "    return mod\n",
    "\n",
    "mod = fit()\n",
    "pprint(mod.get_state_tree()['trainable_variables'], indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save_weights(\"models/kbd_model_new.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.08942068, 0.32744282, 0.28887108, 0.29426536], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.softmax(ops.array([-0.66441685,  0.63354456,  0.50821155,  0.526713  ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.5270485, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.sigmoid(0.1083)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "critic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

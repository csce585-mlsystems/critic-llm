{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rho_plus as rp\n",
    "\n",
    "is_dark = False\n",
    "theme, cs = rp.mpl_setup(is_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from critic.kbd_layout import QWERTY\n",
    "from critic.kbd_model import KbdModel\n",
    "from critic.string_alignment import all_paths\n",
    "from critic.corrector import Corrections\n",
    "from dataclasses import dataclass\n",
    "from keras import ops\n",
    "import pickle\n",
    "\n",
    "@dataclass\n",
    "class CorrectionResult:\n",
    "    true: str\n",
    "    typed: str\n",
    "    corrs: Corrections\n",
    "    context: str\n",
    "    time: float\n",
    "\n",
    "class AdjustedKbdModel(KbdModel):\n",
    "    def call(self, inputs):\n",
    "        X, same_i, true_i = inputs\n",
    "        probs = self.log_prob(X[:, 2], X[:, 3:5], X[:, 5:7])\n",
    "        path_log_probs = ops.segment_sum(probs, X[:, 1], num_segments=1000)\n",
    "        path_corr_is = ops.segment_max(X[:, 0], X[:, 1], num_segments=1000)\n",
    "        \n",
    "        yhat = ops.segment_max(path_log_probs, path_corr_is, num_segments=100)\n",
    "        yhat = ops.log_softmax(yhat.at[same_i].set(0).at[-1].set(-np.inf))\n",
    "\n",
    "        return -yhat[true_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CorrectionResult(true='million', typed='million', corrs=Corrections(words=['million', 'mullion', 'millions', 'gillion', 'pillion', 'billion', 'zillion', 'mil lion', 'mil-lion', 'mill ion', 'mill-ion', 'milling', 'milliner'], probs=array([1.47925184e-01, 4.46878511e-07, 1.07528916e-01, 2.13066060e-07,\n",
       "       8.39868496e-07, 1.81012676e-01, 1.13113114e-05, 3.54274769e-07,\n",
       "       2.83182178e-08, 1.15190670e-04, 1.26088814e-06, 5.63057794e-01,\n",
       "       3.45786135e-04])), context='', time=0.2963411490054568)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = QWERTY\n",
    "\n",
    "with open('results/lm_probs.pkl', 'rb') as f:\n",
    "    lms = pickle.load(f)\n",
    "\n",
    "lms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from critic.string_alignment import align, all_paths\n",
    "\n",
    "\n",
    "inputs = []\n",
    "for res in lms[::5]:\n",
    "    if res.true not in res.corrs.words:\n",
    "        continue\n",
    "\n",
    "    corrs = res.corrs.as_series().sort_values(ascending=False)\n",
    "    true_i = np.argmax(corrs.index == res.true)\n",
    "    same_i = np.argmax(corrs.index == res.typed) if res.typed in corrs.index else -1\n",
    "\n",
    "\n",
    "    X = []\n",
    "    i = 0\n",
    "    for corr_i, word in enumerate(corrs.index):\n",
    "        edit_paths = align(res.typed, word)    \n",
    "        paths = all_paths(max(edit_paths.keys()), edit_paths)    \n",
    "\n",
    "        x0s = []\n",
    "        x1s = []\n",
    "        x2s = []\n",
    "        xis = []\n",
    "        xcs = []\n",
    "        for path_i, path in enumerate(paths):\n",
    "            x0 = []\n",
    "            x1 = []\n",
    "            x2 = []\n",
    "            for edit in path:\n",
    "                if edit is not None:\n",
    "                    kind, wrong, right = edit.as_numerical(layout)\n",
    "                    x0.append(kind)\n",
    "                    x1.append(list(wrong))\n",
    "                    x2.append(list(right))\n",
    "\n",
    "            if sum(ops.array(x0).shape) > 0:\n",
    "                x0s.append(ops.array(x0))\n",
    "                x1s.append(ops.array(x1))\n",
    "                x2s.append(ops.array(x2))\n",
    "                xcs.append(ops.zeros_like(x0s[-1]) + corr_i) \n",
    "                xis.append(ops.zeros_like(x0s[-1]) + i)\n",
    "                i += 1\n",
    "\n",
    "\n",
    "        if ops.array(xis).nbytes > 0:        \n",
    "            X0, X1, X2, Xi, Xc = list(map(np.concat, (x0s, x1s, x2s, xis, xcs)))\n",
    "            row = ops.concatenate((Xc[:, None], Xi[:, None], X0[:, None], X1, X2), axis=1)\n",
    "            X.append(row)\n",
    "\n",
    "    X = ops.concatenate(X, axis=0)        \n",
    "    inputs.append([X, ops.array([same_i]), ops.array([true_i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 79ms/step - loss: 0.7591\n",
      "Epoch 2/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - loss: 0.6869 \n",
      "Epoch 3/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - loss: 0.6394\n",
      "Epoch 4/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - loss: 0.6071\n",
      "Epoch 5/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - loss: 0.5844\n",
      "Epoch 6/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - loss: 0.5680\n",
      "Epoch 7/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - loss: 0.5558\n",
      "Epoch 8/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.5465\n",
      "Epoch 9/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.5393\n",
      "Epoch 10/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - loss: 0.5336\n",
      "Epoch 11/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - loss: 0.5291\n",
      "Epoch 12/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.5253\n",
      "Epoch 13/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - loss: 0.5223\n",
      "Epoch 14/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - loss: 0.5197\n",
      "Epoch 15/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - loss: 0.5176\n",
      "Epoch 16/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - loss: 0.5158\n",
      "Epoch 17/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - loss: 0.5143\n",
      "Epoch 18/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - loss: 0.5130\n",
      "Epoch 19/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - loss: 0.5120\n",
      "Epoch 20/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - loss: 0.5111\n",
      "Epoch 21/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - loss: 0.5104\n",
      "Epoch 22/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - loss: 0.5099\n",
      "Epoch 23/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - loss: 0.5095\n",
      "Epoch 24/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - loss: 0.5092\n",
      "Epoch 25/25\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - loss: 0.5090\n",
      "        loss\n",
      "0   1.114254\n",
      "1   1.004853\n",
      "2   0.928531\n",
      "3   0.873556\n",
      "4   0.832636\n",
      "5   0.801258\n",
      "6   0.776583\n",
      "7   0.756856\n",
      "8   0.740862\n",
      "9   0.727686\n",
      "10  0.716694\n",
      "11  0.707435\n",
      "12  0.699578\n",
      "13  0.692877\n",
      "14  0.687145\n",
      "15  0.682239\n",
      "16  0.678047\n",
      "17  0.674482\n",
      "18  0.671473\n",
      "19  0.668969\n",
      "20  0.666925\n",
      "21  0.665309\n",
      "22  0.664097\n",
      "23  0.663269\n",
      "24  0.662817\n",
      "{ 'adjusted_kbd_model_60': { 'aspect_ratio': Array(0.1083018, dtype=float32),\n",
      "                             'oist': Array([-0.66441685,  0.63354456,  0.50821155,  0.526713  ], dtype=float32),\n",
      "                             'power': Array(1.765511, dtype=float32),\n",
      "                             'scale': Array(0.64481956, dtype=float32),\n",
      "                             'tilt': Array(0.09425967, dtype=float32),\n",
      "                             'two_hand': Array(-0.26425606, dtype=float32),\n",
      "                             'vowel': Array(0.30106196, dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from pprint import pprint\n",
    "\n",
    "from keras.optimizers.schedules import PolynomialDecay\n",
    "\n",
    "keras.config.disable_traceback_filtering()\n",
    "\n",
    "\n",
    "def dl():\n",
    "    while True:\n",
    "        for x in inputs:\n",
    "            yield (x, ops.array([0.0]))\n",
    "\n",
    "def fit(epochs=25):\n",
    "    mod = AdjustedKbdModel()    \n",
    "    mod(next(dl())[0])\n",
    "\n",
    "    steps_in_epoch = len(inputs)\n",
    "\n",
    "    decay_steps = steps_in_epoch * epochs\n",
    "\n",
    "    def log_prob_loss(y_true, y_pred):\n",
    "        return y_pred\n",
    "\n",
    "    mod.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=PolynomialDecay(\n",
    "                1e-3, decay_steps, end_learning_rate=1e-6\n",
    "            ),\n",
    "            global_clipnorm=3.0,\n",
    "        ),\n",
    "        loss=log_prob_loss,\n",
    "    )\n",
    "\n",
    "    history = mod.fit(\n",
    "        dl(),\n",
    "        steps_per_epoch=steps_in_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "\n",
    "    print(pd.DataFrame(history.history))\n",
    "\n",
    "    return mod\n",
    "\n",
    "mod = fit()\n",
    "pprint(mod.get_state_tree()['trainable_variables'], indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save_weights(\"models/kbd_model_new.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "critic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (256) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-d83e3400-6cab-452c-8ef7-9feed03060cc',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1732055183,\n",
       " 'model': 'models/llama-3.2-1b-q4_k_m.gguf',\n",
       " 'choices': [{'text': 'Q: Name the planets in the solar system? A: \\xa0Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune, Pluto.',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 14, 'completion_tokens': 21, 'total_tokens': 35}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "      model_path=\"models/llama-3.2-1b-q4_k_m.gguf\",     \n",
    "      logits_all=True,\n",
    "      # n_gpu_layers=-1, # Uncomment to use GPU acceleration\n",
    "      # seed=1337, # Uncomment to set a specific seed\n",
    "      n_ctx=256, # Uncomment to increase the context window\n",
    "      verbose=False\n",
    ")\n",
    "output = llm(\n",
    "      \"Q: Name the planets in the solar system? A: \", # Prompt\n",
    "      max_tokens=32, # Generate up to 32 tokens, set to None to generate up to the end of the context window\n",
    "      stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "      echo=True # Echo the prompt back in the output\n",
    ") # Generate a completion, can also call create_completion\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.328393  ,  9.315139  , 13.538727  , ..., -3.964694  ,\n",
       "        -3.9547782 , -3.9613338 ],\n",
       "       [11.619879  ,  8.614389  , 11.802215  , ..., -0.8710692 ,\n",
       "        -0.8647344 , -0.8702641 ],\n",
       "       [ 8.647881  ,  8.362709  ,  7.0310984 , ...,  0.35414845,\n",
       "         0.35874563,  0.35681295],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option_strs = ['tere', 'tear', 'tree', 'terr', 'ere', 'tee', 'terse', 'there', 'sere', 'tire', 'tare', 'tern', 'tore', 'term', 'mere', 'here', 'were']\n",
    "\n",
    "prefix = llm.tokenize(\"That's neither here nor\".encode(\"utf-8\"), add_bos=True)\n",
    "suffixes = [llm.tokenize((' ' + opt).encode('utf-8'), add_bos=False) for opt in option_strs]\n",
    "\n",
    "options = [prefix + suff for suff in suffixes]\n",
    "\n",
    "opt = options[0]\n",
    "llm.eval(opt)\n",
    "llm.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmiklaucic/miniconda3/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<critic.kbd_corrector.KbdCorrector at 0x7cd1617fa5d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import log_softmax, softmax\n",
    "from critic import load_kbd_corrector\n",
    "corrector = load_kbd_corrector()\n",
    "corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lm</th>\n",
       "      <th>kbd</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>-3.544963</td>\n",
       "      <td>0.073214</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>-5.896239</td>\n",
       "      <td>0.049498</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas</th>\n",
       "      <td>-15.789628</td>\n",
       "      <td>0.516122</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gasp</th>\n",
       "      <td>-17.341921</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gauss</th>\n",
       "      <td>-18.228764</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gal</th>\n",
       "      <td>-12.780021</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gar</th>\n",
       "      <td>-15.490807</td>\n",
       "      <td>0.057191</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gays</th>\n",
       "      <td>-16.528717</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gabs</th>\n",
       "      <td>-18.975555</td>\n",
       "      <td>0.011507</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gash</th>\n",
       "      <td>-19.964802</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gags</th>\n",
       "      <td>-16.414463</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaps</th>\n",
       "      <td>-16.194153</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sag</th>\n",
       "      <td>-14.458327</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gads</th>\n",
       "      <td>-20.023438</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gals</th>\n",
       "      <td>-17.567719</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gars</th>\n",
       "      <td>-20.840588</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs</th>\n",
       "      <td>-16.443659</td>\n",
       "      <td>0.049498</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gad</th>\n",
       "      <td>-17.234632</td>\n",
       "      <td>0.073214</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaze</th>\n",
       "      <td>-16.938345</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lm       kbd   prob\n",
       "has    -3.544963  0.073214  0.939\n",
       "as     -5.896239  0.049498  0.060\n",
       "gas   -15.789628  0.516122  0.000\n",
       "gasp  -17.341921  0.010907  0.000\n",
       "Gauss -18.228764  0.000173  0.000\n",
       "gal   -12.780021  0.061249  0.000\n",
       "gar   -15.490807  0.057191  0.000\n",
       "gays  -16.528717  0.011489  0.000\n",
       "gabs  -18.975555  0.011507  0.000\n",
       "gash  -19.964802  0.011469  0.000\n",
       "gags  -16.414463  0.013397  0.000\n",
       "gaps  -16.194153  0.011414  0.000\n",
       "sag   -14.458327  0.008572  0.000\n",
       "gads  -20.023438  0.014747  0.000\n",
       "gals  -17.567719  0.012337  0.000\n",
       "gars  -20.840588  0.011519  0.000\n",
       "gs    -16.443659  0.049498  0.000\n",
       "gad   -17.234632  0.073214  0.000\n",
       "gaze  -16.938345  0.002484  0.000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "text = \"The coverage about me in the paper gas\"\n",
    "cache_state = False\n",
    "\n",
    "\n",
    "prefix, suffix = text.rsplit(' ', maxsplit=1)\n",
    "corrector.clear_context()\n",
    "corrector.push_words(prefix)\n",
    "corrs = corrector.correct(suffix)\n",
    "\n",
    "prefix = llm.tokenize(prefix.encode('utf-8'), add_bos=True)\n",
    "suffixes = [llm.tokenize((' ' + opt).encode('utf-8'), add_bos=False) for opt in corrs.words]\n",
    "num_prefix = len(prefix)\n",
    "\n",
    "if cache_state:\n",
    "    llm.reset()\n",
    "    llm.eval(prefix)\n",
    "    state = llm.save_state()\n",
    "\n",
    "opt_scores = []\n",
    "for suff in suffixes:\n",
    "    if cache_state:\n",
    "        llm.load_state(state)\n",
    "        llm.eval(suff)\n",
    "    else:\n",
    "        llm.reset()\n",
    "        llm.eval(prefix + suff)    \n",
    "\n",
    "    logits = llm.scores[num_prefix - 1 : num_prefix + len(suffix) - 1, :]\n",
    "    pad_mask = np.arange(llm.n_ctx()) < (num_prefix +len(suffix))\n",
    "\n",
    "    labels = suff\n",
    "\n",
    "    log_probs = log_softmax(logits, axis=1)\n",
    "    scores = log_probs[np.arange(len(labels)), labels]\n",
    "\n",
    "    score = np.sum(scores)\n",
    "    opt_scores.append(score)\n",
    "\n",
    "df = pd.DataFrame({'lm': opt_scores, 'kbd': corrs.probs}, index=corrs.words)\n",
    "df['prob'] = softmax(df['lm'] + np.log(df['kbd'])).round(3)\n",
    "df.sort_values('prob', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
